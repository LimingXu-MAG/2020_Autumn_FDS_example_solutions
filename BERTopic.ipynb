{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTopic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LimingXu-MAG/2020_Autumn_FDS_example_solutions/blob/main/BERTopic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXHLDxJdRzBi"
      },
      "source": [
        "# **BERTopic - Tutorial**\n",
        "We start with installing bertopic from pypi before preparing the data. \n",
        "\n",
        "**NOTE**: Make sure to select a GPU runtime. Otherwise, the model can take quite some time to create the document embeddings!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNa-KtKDRnus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb764ed8-11be-4a37-aeb1-e89acbc10c6c"
      },
      "source": [
        "!pip install bertopic[visualization]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bertopic[visualization]\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/a5/700851ac2bc1068462b8ee18b52b54a6716b4f90d758b232105b50c9f227/bertopic-0.4.3-py2.py3-none-any.whl\n",
            "Collecting joblib==0.17.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl (301kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.6/dist-packages (from bertopic[visualization]) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.6/dist-packages (from bertopic[visualization]) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from bertopic[visualization]) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from bertopic[visualization]) (1.7.0+cu101)\n",
            "Requirement already satisfied: umap-learn>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from bertopic[visualization]) (0.4.6)\n",
            "Collecting hdbscan>=0.8.26\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/2f/2423d844072f007a74214c1adc46260e45f034bb1679ccadfbb8a601f647/hdbscan-0.8.26.tar.gz (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 15.4MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.6/dist-packages (from bertopic[visualization]) (4.41.1)\n",
            "Collecting sentence-transformers>=0.3.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/e2/84d6acfcee2d83164149778a33b6bdd1a74e1bcb59b2b2cd1b861359b339/sentence-transformers-0.4.1.2.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.6/dist-packages (from bertopic[visualization]) (1.1.5)\n",
            "Collecting plotly<4.14.3,>=4.7.0; extra == \"visualization\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2e/69579c3db25fa4f85d70a10f8a98d52c2b4a0dcbd153e8f17f425761bef4/plotly-4.14.2-py2.py3-none-any.whl (13.2MB)\n",
            "\u001b[K     |████████████████████████████████| 13.2MB 255kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2; extra == \"visualization\" in /usr/local/lib/python3.6/dist-packages (from bertopic[visualization]) (3.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->bertopic[visualization]) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->bertopic[visualization]) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->bertopic[visualization]) (3.7.4.3)\n",
            "Requirement already satisfied: numba!=0.47,>=0.46 in /usr/local/lib/python3.6/dist-packages (from umap-learn>=0.4.6->bertopic[visualization]) (0.48.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hdbscan>=0.8.26->bertopic[visualization]) (1.15.0)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.6/dist-packages (from hdbscan>=0.8.26->bertopic[visualization]) (0.29.21)\n",
            "Collecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/40/866cbfac4601e0f74c7303d533a9c5d4a53858bd402e08e3e294dd271f25/transformers-4.2.1-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 55.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers>=0.3.9->bertopic[visualization]) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.5->bertopic[visualization]) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.5->bertopic[visualization]) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly<4.14.3,>=4.7.0; extra == \"visualization\"->bertopic[visualization]) (1.3.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.2; extra == \"visualization\"->bertopic[visualization]) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.2; extra == \"visualization\"->bertopic[visualization]) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.2; extra == \"visualization\"->bertopic[visualization]) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba!=0.47,>=0.46->umap-learn>=0.4.6->bertopic[visualization]) (51.1.2)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba!=0.47,>=0.46->umap-learn>=0.4.6->bertopic[visualization]) (0.31.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.9->bertopic[visualization]) (20.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.9->bertopic[visualization]) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.9->bertopic[visualization]) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.9->bertopic[visualization]) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 53.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.9->bertopic[visualization]) (3.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.9->bertopic[visualization]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.9->bertopic[visualization]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.9->bertopic[visualization]) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.9->bertopic[visualization]) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.9->bertopic[visualization]) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.9->bertopic[visualization]) (3.4.0)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.26-cp36-cp36m-linux_x86_64.whl size=2301760 sha256=53b383ff11d91b92d319f36f3ce726c38601effed08ef7e4be5da28128b66bd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/38/41/372f034d8abd271ef7787a681e0a47fc05d472683a7eb088ed\n",
            "Successfully built hdbscan\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.1.2-cp36-none-any.whl size=103068 sha256=5923fa19da30761b715c3fc03e06434ea6b8f9e4d89ce9f5f9f948795664ff16\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/33/d1/5703dd56199c09d4a1b41e0c07fb4e7765a84d787cbdc48ac3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=11e237af94b695156eaa34bfff39089fa0fc03e69285dbee79563eb209a4d17f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: joblib, hdbscan, tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers, plotly, bertopic\n",
            "  Found existing installation: joblib 1.0.0\n",
            "    Uninstalling joblib-1.0.0:\n",
            "      Successfully uninstalled joblib-1.0.0\n",
            "  Found existing installation: plotly 4.4.1\n",
            "    Uninstalling plotly-4.4.1:\n",
            "      Successfully uninstalled plotly-4.4.1\n",
            "Successfully installed bertopic-0.4.3 hdbscan-0.8.26 joblib-0.17.0 plotly-4.14.2 sacremoses-0.0.43 sentence-transformers-0.4.1.2 sentencepiece-0.1.95 tokenizers-0.9.4 transformers-4.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3VGFZ1USMTu"
      },
      "source": [
        "# **Prepare data**\n",
        "For this example, we use the popular 20 Newsgroups dataset which contains roughly 18000 newsgroups posts on 20 topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJij3WP6SEQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35126496-f54f-453e-893e-ae1174182bf9"
      },
      "source": [
        "from bertopic import BERTopic\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        " \n",
        "docs = pd.read_csv('customer_survey_comments.csv')['comments']\n",
        "\n",
        "docs"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       I know that there is a shortage of skilled eng...\n",
              "1       We had a bit bad luck on that day, one of thei...\n",
              "2       It is quite easy to order parts..I just ring a...\n",
              "3                                          No not really.\n",
              "4       Stop phoning me for a stupid survey everytime ...\n",
              "                              ...                        \n",
              "3483                    A delivery service would be nice.\n",
              "3484                                I have had no issues.\n",
              "3485                                    Cut their prices.\n",
              "3486                                  No problems at all.\n",
              "3487    Talk to me on the phone not email, get the job...\n",
              "Name: comments, Length: 3488, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j-ezZtq-Gw9"
      },
      "source": [
        "Remove stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ5j-uPm-EW-"
      },
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "# Remove stopwords\n",
        "docs = docs.apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGk1cVDOrKxd",
        "outputId": "31020f28-ee06-4390-f864-bac2d3bb6f6e"
      },
      "source": [
        "docs"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       I know shortage skilled engineers. If improve ...\n",
              "1       We bit bad luck day, guys sick. But best keepi...\n",
              "2       It easy order parts..I ring number speak them....\n",
              "3                                              No really.\n",
              "4       Stop phoning stupid survey everytime I order p...\n",
              "                              ...                        \n",
              "3483                             A delivery service nice.\n",
              "3484                                            I issues.\n",
              "3485                                          Cut prices.\n",
              "3486                                     No problems all.\n",
              "3487                         Talk phone email, job right.\n",
              "Name: comments, Length: 3488, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBcNmZJzSTY8"
      },
      "source": [
        "# **Create Topics**\n",
        "We select the \"english\" as the main language for our documents. If you want a multilingual model that supports 50+ languages, please select \"multilingual\" instead. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfhfzqkoSJ1I"
      },
      "source": [
        "# sentence_model = SentenceTransformer(\"distilbert-base-nli-mean-tokens\")\n",
        "# embeddings = sentence_model.encode(docs, show_progress_bar=False)\n",
        "\n",
        "# # Create topic model\n",
        "# model = BERTopic()\n",
        "# topics, probs = model.fit_transform(docs, embeddings)\n",
        "\n",
        "model = BERTopic(language=\"english\")\n",
        "topics, probs = model.fit_transform(docs)\n",
        "\n",
        "top_k = 5\n",
        "\n",
        "# Further reduce topics \n",
        "new_topics, new_probs = model.reduce_topics(docs, topics, probs, nr_topics=top_k)\n",
        "\n",
        "# Save the topics and their probabilities \n",
        "topics = model.get_topics()\n",
        "i=0\n",
        "topic_df = pd.DataFrame()\n",
        "for k, v in topics.items():\n",
        "  words, probs = [], []\n",
        "  for w, p in v:\n",
        "    words.append(w)\n",
        "    probs.append(p)\n",
        "  topic_df['topic[' + str(i) + ']_words'] = words\n",
        "  topic_df['topic[' + str(i) + ']_probs'] = probs\n",
        "  i += 1\n",
        "\n",
        "topic_df.to_csv(f'top{top_k}_topics.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0SBRlDXLHsR"
      },
      "source": [
        "topic_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ua80usww-rj"
      },
      "source": [
        "We can then extract most frequent topics:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BtOgifV7Q-H"
      },
      "source": [
        "-1 refers to all outliers and should typically be ignored. Next, let's take a look at the most frequent topic that was generated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNptKBzHSbyS"
      },
      "source": [
        "model.visualize_topics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCw_q8I7Sb03"
      },
      "source": [
        "model.get_topic(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_XSeuhs7bpK"
      },
      "source": [
        "Note that the model is stocastich which mmeans that the topics might differ across runs. \r\n",
        "\r\n",
        "For a full list of support languages, see the values below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eyImbal7lb8"
      },
      "source": [
        "# **Embedding model**\r\n",
        "You can select any model from `sentence-transformers` and use it instead of the preselected models by simply passing the model through  \r\n",
        "BERTopic with `embedding_model`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dR2ckNK782p"
      },
      "source": [
        "# st_model = BERTopic(embedding_model=\"xlm-r-bert-base-nli-stsb-mean-tokens\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoMc1W-x7-b5"
      },
      "source": [
        "Click [here](https://www.sbert.net/docs/pretrained_models.html) for a list of supported sentence transformers models.  \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8c8LenB8Zyl"
      },
      "source": [
        "# **Visualize Topics**\r\n",
        "After having trained our `BERTopic` model, we can iteratively go through perhaps a hundred topic to get a good \r\n",
        "understanding of the topics that were extract. However, that takes quite some time and lacks a global representation. \r\n",
        "Instead, we can visualize the topics that were generated in a way very similar to \r\n",
        "[LDAvis](https://github.com/cpsievert/LDAvis):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQKBcla28bY0"
      },
      "source": [
        "model.visualize_topics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITB7bf6q8nWQ"
      },
      "source": [
        "# **Visualize Topic Probabilities**\r\n",
        "\r\n",
        "The variable `probabilities` that is returned from `transform()` or `fit_transform()` can \r\n",
        "be used to understand how confident BERTopic is that certain topics can be found in a document. \r\n",
        "\r\n",
        "To visualize the distributions, we simply call:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsd6Uce38bfX"
      },
      "source": [
        "model.visualize_distribution(probs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9antKpdC91A-"
      },
      "source": [
        "# **Topic Reduction**\r\n",
        "Finally, we can also reduce the number of topics after having trained a BERTopic model. The advantage of doing so, \r\n",
        "is that you can decide the number of topics after knowing how many are actually created. It is difficult to \r\n",
        "predict before training your model how many topics that are in your documents and how many will be extracted. \r\n",
        "Instead, we can decide afterwards how many topics seems realistic:\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m4Nd7Us-Peg"
      },
      "source": [
        "new_topics, new_probs = model.reduce_topics(docs, topics, probs, nr_topics=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlTrmhoo-PmV"
      },
      "source": [
        "\r\n",
        "The reasoning for putting `docs`, `topics`, and `probs` as parameters is that these values are not saved within \r\n",
        "BERTopic on purpose. If you were to have a million documents, it seems very inefficient to save those in BERTopic \r\n",
        "instead of a dedicated database.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4m3UMsw-Zxk"
      },
      "source": [
        "# **Topic Representation**\r\n",
        "When you have trained a model and viewed the topics and the words that represent them,\r\n",
        "you might not be satisfied with the representation. Perhaps you forgot to remove\r\n",
        "stop_words or you want to try out a different n_gram_range. We can use the function `update_topics` to update \r\n",
        "the topic representation with new parameters for `c-TF-IDF`: \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWm7B-FJ-iYW"
      },
      "source": [
        "model.update_topics(docs, topics, n_gram_range=(1, 3), stop_words=\"english\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXYJ745O-03Z"
      },
      "source": [
        "# **Search Topics**\r\n",
        "After having trained our model, we can use `find_topics` to search for topics that are similar \r\n",
        "to an input search_term. Here, we are going to be searching for topics that closely relate the \r\n",
        "search term \"vehicle\". Then, we extract the most similar topic and check the results: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eMrXzrWJVys"
      },
      "source": [
        "model.get_topics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zT9pv94t9gp"
      },
      "source": [
        "model.get_topics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAdiVYej-2i-"
      },
      "source": [
        "similar_topics, similarity = model.find_topics(\"parts\", top_n=5); similar_topics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-DaaqSA-2nH"
      },
      "source": [
        "model.get_topic(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wekNoQNuUVoU"
      },
      "source": [
        "# **Model serialization**\n",
        "The model and its internal settings can easily be saved. Note that the documents and embeddings will not be saved. However, UMAP and HDBSCAN will be saved. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWUF1uxiSb_a"
      },
      "source": [
        "# Save model\n",
        "model.save(\"my_model\")\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_eHBI1jSb6i"
      },
      "source": [
        "# Load model\n",
        "my_model = BERTopic.load(\"my_model\")\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo6_qYKIyJhk"
      },
      "source": [
        "[1, 5 for i in range(3)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSGrN-uxV6je"
      },
      "source": [
        "5 // 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYNWeEzmdrmw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}